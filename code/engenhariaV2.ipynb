{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas para os dados de produção:\n",
      "Acurácia: 0.6\n",
      "Precisão: 0.6\n",
      "Recall: 1.0\n",
      "F1-Score: 0.7499999999999999\n",
      "Log Loss: 0.6931471805599453\n",
      "\n",
      "Métricas para os dados de desenvolvimento:\n",
      "Acurácia: 0.6\n",
      "Precisão: 0.6\n",
      "Recall: 1.0\n",
      "F1-Score: 0.7499999999999999\n",
      "Log Loss: 0.8171703953063254\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss\n",
    "\n",
    "# Dados de produção\n",
    "predicted_probs_prod = [0.5, 0.5, 0.5, 0.5, 0.5]  # Substitua pelos valores reais\n",
    "real_results_prod = [0, 1, 1, 0, 1]  # Substitua pelos valores reais\n",
    "\n",
    "# Dados de desenvolvimento\n",
    "predicted_probs_dev = [0.5, 0.5, 0.5, 0.731059, 0.5]  # Substitua pelos valores reais\n",
    "real_results_dev = [0, 1, 1, 0, 1]  # Substitua pelos valores reais\n",
    "\n",
    "# Calcular as métricas para os dados de produção\n",
    "accuracy_prod = accuracy_score(real_results_prod, [1 if p >= 0.5 else 0 for p in predicted_probs_prod])\n",
    "precision_prod = precision_score(real_results_prod, [1 if p >= 0.5 else 0 for p in predicted_probs_prod])\n",
    "recall_prod = recall_score(real_results_prod, [1 if p >= 0.5 else 0 for p in predicted_probs_prod])\n",
    "f1_prod = f1_score(real_results_prod, [1 if p >= 0.5 else 0 for p in predicted_probs_prod])\n",
    "logloss_prod = log_loss(real_results_prod, predicted_probs_prod)\n",
    "\n",
    "# Calcular as métricas para os dados de desenvolvimento\n",
    "accuracy_dev = accuracy_score(real_results_dev, [1 if p >= 0.5 else 0 for p in predicted_probs_dev])\n",
    "precision_dev = precision_score(real_results_dev, [1 if p >= 0.5 else 0 for p in predicted_probs_dev])\n",
    "recall_dev = recall_score(real_results_dev, [1 if p >= 0.5 else 0 for p in predicted_probs_dev])\n",
    "f1_dev = f1_score(real_results_dev, [1 if p >= 0.5 else 0 for p in predicted_probs_dev])\n",
    "logloss_dev = log_loss(real_results_dev, predicted_probs_dev)\n",
    "\n",
    "# Imprimir as métricas\n",
    "print(\"Métricas para os dados de produção:\")\n",
    "print(f\"Acurácia: {accuracy_prod}\")\n",
    "print(f\"Precisão: {precision_prod}\")\n",
    "print(f\"Recall: {recall_prod}\")\n",
    "\n",
    "print(f\"F1-Score: {f1_prod}\")\n",
    "print(f\"Log Loss: {logloss_prod}\")\n",
    "print(\"\\nMétricas para os dados de desenvolvimento:\")\n",
    "print(f\"Acurácia: {accuracy_dev}\")\n",
    "print(f\"Precisão: {precision_dev}\")\n",
    "print(f\"Recall: {recall_dev}\")\n",
    "print(f\"F1-Score: {f1_dev}\")\n",
    "print(f\"Log Loss: {logloss_dev}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de produção:\n",
      "   probability\n",
      "0          0.5\n",
      "1          0.5\n",
      "2          0.5\n",
      "3          0.5\n",
      "4          0.5\n",
      "\n",
      "Dados de desenvolvimento:\n",
      "   probability\n",
      "0     0.500000\n",
      "1     0.500000\n",
      "2     0.500000\n",
      "3     0.731059\n",
      "4     0.500000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carregar os dados de produção\n",
    "prod_data_path = \"C:/Users/Anderson/Desktop/REDES_NEURAIS/ENGENHARIA_V2/code/predictions_prod_2024-05-09_22-28-49.parquet\"\n",
    "prod_data = pd.read_parquet(prod_data_path)\n",
    "\n",
    "# Carregar os dados de desenvolvimento\n",
    "dev_data_path = \"C:/Users/Anderson/Desktop/REDES_NEURAIS/ENGENHARIA_V2/code/predictions_dev_2024-05-09_22-34-50.parquet\"\n",
    "dev_data = pd.read_parquet(dev_data_path)\n",
    "\n",
    "# Visualizar os dados\n",
    "print(\"Dados de produção:\")\n",
    "print(prod_data.head())\n",
    "\n",
    "print(\"\\nDados de desenvolvimento:\")\n",
    "print(dev_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Loaded\n",
      "Resultados do modelo para os dados de desenvolvimento:\n",
      "Log Loss: 6.7659844798136985\n",
      "F1 Score: 0.5223325750430006\n",
      "\n",
      "Resultados do modelo para os dados de produção:\n",
      "Log Loss: 5.252267767958857\n",
      "F1 Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "from sklearn.metrics import log_loss, f1_score\n",
    "from pycaret.classification import load_model\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "def load_production_data(file_path):\n",
    "    # Carregar a base de produção\n",
    "    prod_data = pd.read_parquet(file_path)\n",
    "    return prod_data\n",
    "\n",
    "def load_dev_data(file_path):\n",
    "    # Carregar a base de desenvolvimento\n",
    "    dev_data = pd.read_parquet(file_path)\n",
    "    return dev_data\n",
    "\n",
    "def apply_model(model, data):\n",
    "    # Aplicar o modelo aos dados e obter as pontuações\n",
    "    scores = model.predict(data)\n",
    "    # Aplicar função sigmoid para transformar em probabilidades\n",
    "    probabilities = 1 / (1 + np.exp(-scores))\n",
    "    return probabilities\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    # Avaliar o modelo com os dados\n",
    "    y_pred = model.predict(X)\n",
    "    logloss = log_loss(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    return logloss, f1\n",
    "\n",
    "def compare_datasets(dev_data, prod_data):\n",
    "    # Comparar resultados do modelo entre os conjuntos de dados\n",
    "    logloss_dev, f1_dev = evaluate_model(model, dev_data.drop(columns=['shot_made_flag']), dev_data['shot_made_flag'])\n",
    "    logloss_prod, f1_prod = evaluate_model(model, prod_data.drop(columns=['shot_made_flag']), prod_data['shot_made_flag'])\n",
    "\n",
    "    print(\"Resultados do modelo para os dados de desenvolvimento:\")\n",
    "    print(\"Log Loss:\", logloss_dev)\n",
    "    print(\"F1 Score:\", f1_dev)\n",
    "    print()\n",
    "\n",
    "    print(\"Resultados do modelo para os dados de produção:\")\n",
    "    print(\"Log Loss:\", logloss_prod)\n",
    "    print(\"F1 Score:\", f1_prod)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Carregar o modelo treinado\n",
    "    model_path = \"C:/Users/Anderson/Desktop/REDES_NEURAIS/ENGENHARIA_V2/code/mlruns/216971763806645027/4dbe79efd23f4d4984b0522e3ad0bd46/artifacts/model/model\"\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    # Carregar os dados de produção\n",
    "    production_data_path = \"C:/Users/Anderson/Desktop/REDES_NEURAIS/ENGENHARIA_V2/data/processed/data_filtered_prod.parquet\"\n",
    "    prod_data = load_production_data(production_data_path)\n",
    "\n",
    "    # Carregar os dados de desenvolvimento\n",
    "    dev_data_path = \"C:/Users/Anderson/Desktop/REDES_NEURAIS/ENGENHARIA_V2/data/processed/data_filtered_dev.parquet\"\n",
    "    dev_data = load_dev_data(dev_data_path)\n",
    "\n",
    "    # Comparar resultados do modelo entre os conjuntos de dados\n",
    "    compare_datasets(dev_data, prod_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Loaded\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "from sklearn.metrics import log_loss, f1_score\n",
    "from pycaret.classification import load_model\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "def load_production_data(file_path):\n",
    "    # Carregar a base de produção\n",
    "    prod_data = pd.read_parquet(file_path)\n",
    "    return prod_data\n",
    "\n",
    "def load_dev_data(file_path):\n",
    "    # Carregar a base de desenvolvimento\n",
    "    dev_data = pd.read_parquet(file_path)\n",
    "    return dev_data\n",
    "\n",
    "def apply_model(model, data):\n",
    "    # Aplicar o modelo aos dados e obter as pontuações\n",
    "    scores = model.predict(data)\n",
    "    # Aplicar função sigmoid para transformar em probabilidades\n",
    "    probabilities = 1 / (1 + np.exp(-scores))\n",
    "    return probabilities\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    # Avaliar o modelo com os dados\n",
    "    y_pred = model.predict(X)\n",
    "    logloss = log_loss(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    return logloss, f1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Carregar o modelo treinado\n",
    "    model_path = \"C:/Users/Anderson/Desktop/REDES_NEURAIS/ENGENHARIA_V2/code/mlruns/216971763806645027/4dbe79efd23f4d4984b0522e3ad0bd46/artifacts/model/model\"\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    # Carregar os dados de produção\n",
    "    production_data_path = \"C:/Users/Anderson/Desktop/REDES_NEURAIS/ENGENHARIA_V2/data/processed/data_filtered_prod.parquet\"\n",
    "    prod_data = load_production_data(production_data_path)\n",
    "\n",
    "    # Carregar os dados de desenvolvimento\n",
    "    dev_data_path = \"C:/Users/Anderson/Desktop/REDES_NEURAIS/ENGENHARIA_V2/data/processed/data_filtered_dev.parquet\"\n",
    "    dev_data = load_dev_data(dev_data_path)\n",
    "\n",
    "    # Aplicar o modelo aos dados de produção\n",
    "    predictions_prod = apply_model(model, prod_data.drop(columns=['shot_made_flag']))\n",
    "\n",
    "    # Avaliar o modelo com os dados de produção\n",
    "    logloss_prod, f1_prod = evaluate_model(model, prod_data.drop(columns=['shot_made_flag']), prod_data['shot_made_flag'])\n",
    "\n",
    "    # Aplicar o modelo aos dados de desenvolvimento\n",
    "    predictions_dev = apply_model(model, dev_data.drop(columns=['shot_made_flag']))\n",
    "\n",
    "    # Avaliar o modelo com os dados de desenvolvimento\n",
    "    logloss_dev, f1_dev = evaluate_model(model, dev_data.drop(columns=['shot_made_flag']), dev_data['shot_made_flag'])\n",
    "\n",
    "    # Nomear a rodada do MLflow\n",
    "    mlflow.set_experiment(\"PipelineAplicacao\")\n",
    "    with mlflow.start_run(run_name=\"PipelineAplicacao\"):\n",
    "        # Salvar resultados como artefatos\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        \n",
    "        # Converter os arrays numpy em dataframes do pandas\n",
    "        predictions_prod_df = pd.DataFrame(predictions_prod, columns=['probability'])\n",
    "        predictions_dev_df = pd.DataFrame(predictions_dev, columns=['probability'])\n",
    "\n",
    "        # Salvar os dataframes como arquivos parquet\n",
    "        predictions_prod_df.to_parquet(f\"predictions_prod_{timestamp}.parquet\")\n",
    "        predictions_dev_df.to_parquet(f\"predictions_dev_{timestamp}.parquet\")\n",
    "        \n",
    "        # Logar as métricas de produção\n",
    "        mlflow.log_metric(\"log_loss_prod\", logloss_prod)\n",
    "        mlflow.log_metric(\"f1_score_prod\", f1_prod)\n",
    "\n",
    "        # Logar as métricas de desenvolvimento\n",
    "        mlflow.log_metric(\"log_loss_dev\", logloss_dev)\n",
    "        mlflow.log_metric(\"f1_score_dev\", f1_dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A corrida MODELOBOM foi registrada e contém os seguintes artefatos (modelos):\n",
      "file:///c:/Users/Anderson/Desktop/REDES_NEURAIS/ENGENHARIA_V2/code/mlruns/216971763806645027/4dbe79efd23f4d4984b0522e3ad0bd46/artifacts\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Listar todas as corridas\n",
    "runs = mlflow.search_runs()\n",
    "\n",
    "# Filtrar as corridas pelo nome do experimento\n",
    "runs_modelobom = runs[runs['tags.mlflow.runName'] == \"MODELOBOM\"]\n",
    "\n",
    "if not runs_modelobom.empty:\n",
    "    # Se houver corridas com o nome \"MODELOBOM\", obtemos o ID da primeira corrida\n",
    "    run_id = runs_modelobom.iloc[0]['run_id']\n",
    "    \n",
    "    # Obter informações sobre a corrida MODELOBOM\n",
    "    run_info = mlflow.get_run(run_id)\n",
    "    \n",
    "    # Acessar os artefatos (modelos) diretamente\n",
    "    artifacts = run_info.to_dictionary()['info']['artifact_uri']\n",
    "    \n",
    "    if artifacts:\n",
    "        print(\"A corrida MODELOBOM foi registrada e contém os seguintes artefatos (modelos):\")\n",
    "        print(artifacts)\n",
    "    else:\n",
    "        print(\"A corrida MODELOBOM foi registrada, mas não contém modelos.\")\n",
    "else:\n",
    "    print(\"A corrida MODELOBOM não foi registrada no MLflow.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/05/09 21:22:12 INFO mlflow.tracking.fluent: Experiment with name 'Treinamento' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas para Regressão Logística:\n",
      "Log Loss: 0.6783615727270217\n",
      "Métricas para Árvore de Decisão:\n",
      "Log Loss: 4.3672161877959015\n",
      "F1 Score: 0.8137086903304773\n",
      "O melhor modelo é: Regressão Logística\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, f1_score\n",
    "from pycaret.classification import setup, create_model\n",
    "\n",
    "#  MLflow\n",
    "mlflow.set_experiment(\"Treinamento\")\n",
    "\n",
    "#  treinamento e teste filtrados\n",
    "dev_processed_path = \"C:/Users/Anderson/Desktop/REDES_NEURAIS/ENGENHARIA_V2/data/processed/data_filtered_dev.parquet\"\n",
    "prod_processed_path = \"C:/Users/Anderson/Desktop/REDES_NEURAIS/ENGENHARIA_V2/data/processed/data_filtered_prod.parquet\"\n",
    "dev_df = pd.read_parquet(dev_processed_path)\n",
    "prod_df = pd.read_parquet(prod_processed_path)\n",
    "\n",
    "# Separar os dados filtrados para treinamento e teste\n",
    "X_dev = dev_df.drop(columns=['shot_made_flag'])\n",
    "y_dev = dev_df['shot_made_flag']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dev, y_dev, test_size=0.2, stratify=y_dev, random_state=42)\n",
    "\n",
    "# Verificar se uma corrida está ativa\n",
    "if mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "# Iniciar uma nova corrida do MLflow\n",
    "with mlflow.start_run(run_name=\"Treinamento\"):\n",
    "\n",
    "    # Treinar o modelo de regressão logística\n",
    "    with mlflow.start_run(run_name=\"Logistic Regression\", nested=True):\n",
    "        lr_model = create_model('lr', verbose=False)\n",
    "        lr_pred_test = lr_model.predict_proba(X_test)\n",
    "        lr_logloss = log_loss(y_test, lr_pred_test)\n",
    "        mlflow.log_param(\"model\", \"Logistic Regression\")\n",
    "        mlflow.log_metric(\"log_loss\", lr_logloss)\n",
    "        print(f\"Métricas para Regressão Logística:\\nLog Loss: {lr_logloss}\")\n",
    "\n",
    "    #  árvore de decisão\n",
    "    with mlflow.start_run(run_name=\"Decision Tree\", nested=True):\n",
    "        tree_model = create_model('dt', verbose=False)\n",
    "        tree_pred_test = tree_model.predict_proba(X_test)\n",
    "        tree_logloss = log_loss(y_test, tree_pred_test)\n",
    "        tree_f1 = f1_score(y_test, tree_model.predict(X_test))\n",
    "        mlflow.log_param(\"model\", \"Decision Tree\")\n",
    "        mlflow.log_metric(\"log_loss\", tree_logloss)\n",
    "        mlflow.log_metric(\"f1_score\", tree_f1)\n",
    "        print(f\"Métricas para Árvore de Decisão:\\nLog Loss: {tree_logloss}\\nF1 Score: {tree_f1}\")\n",
    "\n",
    "    # Selecionar o modelo com menor log loss para finalização\n",
    "    if lr_logloss < tree_logloss:\n",
    "        best_model = lr_model\n",
    "        best_model_name = \"Regressão Logística\"\n",
    "    else:\n",
    "        best_model = tree_model\n",
    "        best_model_name = \"Árvore de Decisão\"\n",
    "\n",
    "    print(f\"O melhor modelo é: {best_model_name}\")\n",
    "\n",
    "    # Encerrar a corrida atual do MLflow\n",
    "    mlflow.end_run()\n",
    "\n",
    "    # Iniciar uma nova corrida para salvar o melhor modelo\n",
    "    with mlflow.start_run(run_name=\"Melhor Modelo\"):\n",
    "\n",
    "        # Log do modelo\n",
    "        mlflow.sklearn.log_model(best_model, \"model\")\n",
    "\n",
    "        # Log dos parâmetros do modelo\n",
    "        mlflow.log_param(\"model_name\", best_model_name)\n",
    "\n",
    "        # Log das métricas\n",
    "        mlflow.log_metric(\"log_loss\", min(lr_logloss, tree_logloss))\n",
    "        if best_model_name == \"Árvore de Decisão\":\n",
    "            mlflow.log_metric(\"f1_score\", tree_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas presentes nos dados de treinamento:\n",
      "Index(['lat', 'lon', 'minutes_remaining', 'period', 'playoffs',\n",
      "       'shot_distance'],\n",
      "      dtype='object')\n",
      "Colunas presentes nos dados de teste:\n",
      "Index(['lat', 'lon', 'minutes_remaining', 'period', 'playoffs',\n",
      "       'shot_distance'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_59c23_row8_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_59c23\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_59c23_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_59c23_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_59c23_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_59c23_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_59c23_row0_col1\" class=\"data row0 col1\" >241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59c23_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_59c23_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_59c23_row1_col1\" class=\"data row1 col1\" >shot_made_flag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59c23_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_59c23_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_59c23_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59c23_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_59c23_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_59c23_row3_col1\" class=\"data row3 col1\" >(20285, 7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59c23_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_59c23_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_59c23_row4_col1\" class=\"data row4 col1\" >(20285, 7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59c23_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_59c23_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_59c23_row5_col1\" class=\"data row5 col1\" >(14199, 7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59c23_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_59c23_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_59c23_row6_col1\" class=\"data row6 col1\" >(6086, 7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59c23_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_59c23_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n",
       "      <td id=\"T_59c23_row7_col1\" class=\"data row7 col1\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59c23_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_59c23_row8_col0\" class=\"data row8 col0\" >Preprocess</td>\n",
       "      <td id=\"T_59c23_row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59c23_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_59c23_row9_col0\" class=\"data row9 col0\" >Imputation type</td>\n",
       "      <td id=\"T_59c23_row9_col1\" class=\"data row9 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59c23_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_59c23_row10_col0\" class=\"data row10 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_59c23_row10_col1\" class=\"data row10 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59c23_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_59c23_row11_col0\" class=\"data row11 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_59c23_row11_col1\" class=\"data row11 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59c23_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_59c23_row12_col0\" class=\"data row12 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_59c23_row12_col1\" class=\"data row12 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59c23_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_59c23_row13_col0\" class=\"data row13 col0\" >Fold Number</td>\n",
       "      <td id=\"T_59c23_row13_col1\" class=\"data row13 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59c23_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_59c23_row14_col0\" class=\"data row14 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_59c23_row14_col1\" class=\"data row14 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59c23_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_59c23_row15_col0\" class=\"data row15 col0\" >Use GPU</td>\n",
       "      <td id=\"T_59c23_row15_col1\" class=\"data row15 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59c23_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_59c23_row16_col0\" class=\"data row16 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_59c23_row16_col1\" class=\"data row16 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59c23_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_59c23_row17_col0\" class=\"data row17 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_59c23_row17_col1\" class=\"data row17 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59c23_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_59c23_row18_col0\" class=\"data row18 col0\" >USI</td>\n",
       "      <td id=\"T_59c23_row18_col1\" class=\"data row18 col1\" >dcce</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2972071be50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pycaret.classification import setup\n",
    "import mlflow\n",
    "\n",
    "if mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "#  MLflow\n",
    "mlflow.set_experiment(\"PreparacaoDados\")\n",
    "\n",
    "# Iniciar novo  MLflow\n",
    "with mlflow.start_run(run_name=\"PreparacaoDados\"):\n",
    "\n",
    "    # C treinamento e teste\n",
    "    dev_data_path = \"C:/Users/Anderson/Desktop/REDES_NEURAIS/ENGENHARIA_V2/data/raw/dataset_kobe_dev.parquet\"\n",
    "    prod_data_path = \"C:/Users/Anderson/Desktop/REDES_NEURAIS/ENGENHARIA_V2/data/raw/dataset_kobe_prod.parquet\"\n",
    "    dev_df = pd.read_parquet(dev_data_path)\n",
    "    prod_df = pd.read_parquet(prod_data_path)\n",
    "\n",
    "    # colunas necessárias\n",
    "    selected_columns = ['lat', 'lon', 'minutes_remaining', 'period', 'playoffs', 'shot_distance', 'shot_made_flag']\n",
    "    dev_df = dev_df[selected_columns]\n",
    "    prod_df = prod_df[selected_columns]\n",
    "\n",
    "    # Remover linhas com dados faltantes\n",
    "    dev_df.dropna(inplace=True)\n",
    "    prod_df.dropna(inplace=True)\n",
    "\n",
    "    # Salvar o dataset resultante\n",
    "    processed_data_dir = \"C:/Users/Anderson/Desktop/REDES_NEURAIS/ENGENHARIA_V2/data/processed\"\n",
    "    os.makedirs(processed_data_dir, exist_ok=True)\n",
    "    dev_processed_path = os.path.join(processed_data_dir, \"data_filtered_dev.parquet\")\n",
    "    prod_processed_path = os.path.join(processed_data_dir, \"data_filtered_prod.parquet\")\n",
    "    dev_df.to_parquet(dev_processed_path)\n",
    "    prod_df.to_parquet(prod_processed_path)\n",
    "\n",
    "    # Separar os dados em treino e teste (80% treino, 20% teste)\n",
    "    X_dev = dev_df.drop(columns=['shot_made_flag'])\n",
    "    y_dev = dev_df['shot_made_flag']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_dev, y_dev, test_size=0.2, stratify=y_dev, random_state=42)\n",
    "\n",
    "    # Salvar os datasets de treino e teste\n",
    "    train_data_path = os.path.join(processed_data_dir, \"base_train.parquet\")\n",
    "    test_data_path = os.path.join(processed_data_dir, \"base_test.parquet\")\n",
    "    X_train.to_parquet(train_data_path)\n",
    "    y_train.to_frame().to_parquet(train_data_path.replace('.parquet', '_target.parquet'))\n",
    "    X_test.to_parquet(test_data_path)\n",
    "    y_test.to_frame().to_parquet(test_data_path.replace('.parquet', '_target.parquet'))\n",
    "\n",
    "    # Verificar se a coluna shot_made_flag está presente nos dados de treinamento e teste\n",
    "    print(\"Colunas presentes nos dados de treinamento:\")\n",
    "    print(X_train.columns)\n",
    "    print(\"Colunas presentes nos dados de teste:\")\n",
    "    print(X_test.columns)\n",
    "\n",
    "    # Configurar o ambiente de classificação do PyCaret\n",
    "    clf_setup = setup(data=dev_df, target='shot_made_flag')\n",
    "\n",
    "    # Registar os parâmetros no MLflow\n",
    "    mlflow.log_param(\"test_size_percent\", 0.2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "234250f21dfd4e4ef32f5f4db8c2e934a9d2d678166812e687c6eaac9839cad0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
